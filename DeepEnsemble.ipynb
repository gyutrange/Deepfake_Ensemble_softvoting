{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "\n",
        "# Learned Weights for base models:\n",
        "#  - model_A_prob: 0.0163\n",
        "#  - model_B_prob: 0.9710\n",
        "#  - model_C_prob: 0.0127\n",
        "#\n",
        "# --- 설정 (사용자 환경에 맞게 수정) ---\n",
        "# CSV_FILE_PATHS = {\n",
        "#    'FreqNet': '/content/drive/MyDrive/deepfakedetection_csv/FreqNet_Predictions.csv',\n",
        "#    'GenConViT': '/content/drive/MyDrive/deepfakedetection_csv/GenConViT_Predictions.csv',\n",
        "#    'CaFft': '/content/drive/MyDrive/deepfakedetection_csv/CaFft_predictions.csv'\n",
        "    # model: PATH\n",
        "#}\n",
        "# COLUMN NAME SETTING\n",
        "#COLUMN_NAMES = {\n",
        "#     'video_id': 'video_id',\n",
        "#     'FreqNet': {\n",
        "#         'fake_prob': 'fake_prob',\n",
        "#         'true_label': 'true_label'\n",
        "#     },\n",
        "#     'GenConViT': {\n",
        "#         'fake_prob': 'fake_prob',\n",
        "#         # 'true_label': 'true_label'\n",
        "#     },\n",
        "#     'CaFft': {\n",
        "#         'fake_prob': 'fake_prob',\n",
        "#         # 'true_label': 'true_label'\n",
        "#     }\n",
        "# }\n",
        "\n",
        "# # Soft Voting 시 각 모델에 부여할 가중치\n",
        "# MODEL_WEIGHTS = {\n",
        "#     'FreqNet': 0.0163,\n",
        "#     'GenConViT': 0.9710,\n",
        "#     'CaFft': 0.127\n",
        "# } # or None"
      ],
      "metadata": {
        "id": "Gp2yhWzpl6RA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1a4c932-44d3-4bbb-b9a3-15acddba1a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "def prepare_ensemble_csv(\n",
        "    model_csv_paths: dict,\n",
        "    output_dir: str = \"./\",\n",
        "    test_size: float = 0.3,\n",
        "    label_col: str = \"true_label\",\n",
        "    prob_col: str = \"fake_prob\",\n",
        "    id_col: str = \"video_id\",\n",
        "    random_state: int = 42\n",
        "):\n",
        "    \"\"\"\n",
        "    모델 예측 CSV들을 받아 병합하고 validation/test로 나눠 저장.\n",
        "    model_csv_paths: {'model_A': 'path/to/csv1.csv', ...}\n",
        "    output_dir: 저장 경로\n",
        "    \"\"\"\n",
        "    dfs = {}\n",
        "    label_source_df = None\n",
        "\n",
        "    # 각 모델의 예측 결과 로드 및 리네이밍\n",
        "    for model_name, path in model_csv_paths.items():\n",
        "        df = pd.read_csv(path)\n",
        "\n",
        "        # 첫 번째 모델에서 true_label 가져옴\n",
        "        if label_source_df is None and label_col in df.columns:\n",
        "            label_source_df = df[[id_col, label_col]].copy()\n",
        "\n",
        "        if prob_col not in df.columns or id_col not in df.columns:\n",
        "            raise ValueError(f\"{model_name} 파일에 '{prob_col}' 또는 '{id_col}' 컬럼이 없음\")\n",
        "\n",
        "        df = df[[id_col, prob_col]].rename(columns={prob_col: f\"{model_name}_prob\"})\n",
        "        dfs[model_name] = df\n",
        "\n",
        "    # 병합 시작 (model_A부터 시작)\n",
        "    merged_df = list(dfs.values())[0]\n",
        "    for df in list(dfs.values())[1:]:\n",
        "        merged_df = pd.merge(merged_df, df, on=id_col, how=\"inner\")\n",
        "\n",
        "    # true_label 병합\n",
        "    if label_source_df is not None:\n",
        "        merged_df = pd.merge(merged_df, label_source_df, on=id_col, how=\"inner\")\n",
        "\n",
        "        # 문자열 레이블 처리\n",
        "        if merged_df[label_col].dtype == object:\n",
        "            label_map = {\"REAL\": 0, \"FAKE\": 1}\n",
        "            merged_df[label_col] = merged_df[label_col].map(label_map)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"true_label 컬럼을 가진 CSV 파일이 하나 이상 필요합니다.\")\n",
        "\n",
        "    # 정렬\n",
        "    merged_df = merged_df.sort_values(by=id_col).reset_index(drop=True)\n",
        "\n",
        "    # Validation/Test 분할\n",
        "    val_df, test_df = train_test_split(\n",
        "        merged_df, test_size=test_size,\n",
        "        stratify=merged_df[label_col], random_state=random_state\n",
        "    )\n",
        "\n",
        "    # 저장\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    val_path = os.path.join(output_dir, \"validation_predictions.csv\")\n",
        "    test_path = os.path.join(output_dir, \"test_predictions.csv\")\n",
        "    val_df.to_csv(val_path, index=False)\n",
        "    test_df.to_csv(test_path, index=False)\n",
        "\n",
        "    print(f\"[✓] 저장 완료:\\n  Validation: {val_path}\\n  Test: {test_path}\")\n",
        "    return val_df, test_df\n",
        "\n",
        "# --- 사용 예시 ---\n",
        "model_csvs = {\n",
        "    \"model_A\": \"/content/drive/MyDrive/deepfakedetection_csv/FreqNet_Predictions.csv\",\n",
        "    \"model_B\": \"/content/drive/MyDrive/deepfakedetection_csv/GenConViT_Predictions.csv\",\n",
        "    \"model_C\": \"/content/drive/MyDrive/deepfakedetection_csv/CaFft_predictions.csv\",\n",
        "    \"model_D\": \"/content/drive/MyDrive/deepfakedetection_csv/face-x-ray_predictions.csv\",\n",
        "    \"model_E\": \"/content/drive/MyDrive/deepfakedetection_csv/ResNext&LSTM_predictions.csv\"\n",
        "}\n",
        "\n",
        "val_df, test_df = prepare_ensemble_csv(model_csvs, output_dir=\"/content/drive/MyDrive/deepfakedetection_csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcSD0YboFKd6",
        "outputId": "3a9d9779-f556-41e0-aaef-0fa31d1423e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[✓] 저장 완료:\n",
            "  Validation: /content/drive/MyDrive/deepfakedetection_csv/validation_predictions.csv\n",
            "  Test: /content/drive/MyDrive/deepfakedetection_csv/test_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adaptive_ensemble_train.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
        "import logging\n",
        "\n",
        "# --- 로깅 설정 ---\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# --- Adaptive Ensemble Model 정의 ---\n",
        "class AdaptiveWeightedEnsemble(nn.Module):\n",
        "    def __init__(self, num_base_models):\n",
        "        super().__init__()\n",
        "        self.base_model_weights = nn.Parameter(torch.ones(num_base_models) / num_base_models)\n",
        "\n",
        "    def forward(self, base_model_predictions):\n",
        "        normalized_weights = torch.softmax(self.base_model_weights, dim=0)\n",
        "        ensemble_prediction_prob = torch.sum(base_model_predictions * normalized_weights, dim=1).unsqueeze(1)\n",
        "        return ensemble_prediction_prob, normalized_weights\n",
        "\n",
        "    def get_learned_weights(self):\n",
        "        return torch.softmax(self.base_model_weights, dim=0).detach().cpu().numpy()\n",
        "\n",
        "# --- 설정 및 하이퍼파라미터 ---\n",
        "VALIDATION_CSV_PATH = '/content/drive/MyDrive/deepfakedetection_csv/validation_predictions.csv'\n",
        "TEST_CSV_PATH = '/content/drive/MyDrive/deepfakedetection_csv/test_predictions.csv'\n",
        "MODEL_SAVE_PATH = 'adaptive_ensemble_weights.pth'\n",
        "NUM_BASE_MODELS = 3\n",
        "BASE_MODEL_PROB_COLUMNS = ['model_A_prob', 'model_B_prob', 'model_C_prob', 'model_D_prob', 'model_E_prob']\n",
        "LABEL_COLUMN = 'true_label'\n",
        "VIDEO_ID_COLUMN = 'video_id'\n",
        "\n",
        "LEARNING_RATE = 0.01\n",
        "NUM_EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "PATIENCE_EARLY_STOPPING = 10\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "logging.info(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# --- 데이터 로딩 함수 ---\n",
        "def load_data_from_csv(csv_path, prob_columns, label_column):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    X = df[prob_columns].values.astype(np.float32)\n",
        "    y = df[label_column].values.astype(np.float32).reshape(-1, 1)\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "    return X_tensor, y_tensor\n",
        "\n",
        "# --- 메인 실행 ---\n",
        "if __name__ == '__main__':\n",
        "    logging.info(\"Loading validation data...\")\n",
        "    X_val, y_val = load_data_from_csv(VALIDATION_CSV_PATH, BASE_MODEL_PROB_COLUMNS, LABEL_COLUMN)\n",
        "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    logging.info(\"Loading test data...\")\n",
        "    X_test, y_test = load_data_from_csv(TEST_CSV_PATH, BASE_MODEL_PROB_COLUMNS, LABEL_COLUMN)\n",
        "    test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    ensemble_model = AdaptiveWeightedEnsemble(num_base_models=NUM_BASE_MODELS).to(DEVICE)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.AdamW(ensemble_model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    logging.info(\"Starting training of ensemble weights...\")\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        ensemble_model.train()\n",
        "        train_loss_epoch = 0\n",
        "        for batch_X, batch_y in val_loader:\n",
        "            batch_X, batch_y = batch_X.to(DEVICE), batch_y.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            predictions, _ = ensemble_model(batch_X)\n",
        "            loss = criterion(predictions, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss_epoch += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss_epoch / len(val_loader)\n",
        "\n",
        "        ensemble_model.eval()\n",
        "        val_loss_epoch = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_X_val, batch_y_val in val_loader:\n",
        "                batch_X_val, batch_y_val = batch_X_val.to(DEVICE), batch_y_val.to(DEVICE)\n",
        "                val_preds, _ = ensemble_model(batch_X_val)\n",
        "                loss = criterion(val_preds, batch_y_val)\n",
        "                val_loss_epoch += loss.item()\n",
        "\n",
        "        avg_val_loss = val_loss_epoch / len(val_loader)\n",
        "        logging.info(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(ensemble_model.state_dict(), MODEL_SAVE_PATH)\n",
        "            logging.info(f\"Model saved to {MODEL_SAVE_PATH}\")\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve == PATIENCE_EARLY_STOPPING:\n",
        "                logging.info(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    logging.info(\"Training finished.\")\n",
        "\n",
        "    logging.info(\"Evaluating on test set with learned weights...\")\n",
        "    ensemble_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "    ensemble_model.eval()\n",
        "\n",
        "    all_test_preds_probs = []\n",
        "    all_test_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch_X_test, batch_y_test in test_loader:\n",
        "            batch_X_test = batch_X_test.to(DEVICE)\n",
        "            test_preds_probs, _ = ensemble_model(batch_X_test)\n",
        "            all_test_preds_probs.extend(test_preds_probs.cpu().numpy().flatten())\n",
        "            all_test_labels.extend(batch_y_test.cpu().numpy().flatten())\n",
        "\n",
        "    all_test_preds_probs = np.array(all_test_preds_probs)\n",
        "    all_test_labels = np.array(all_test_labels)\n",
        "    all_test_preds_binary = (all_test_preds_probs > 0.5).astype(int)\n",
        "\n",
        "    auc = roc_auc_score(all_test_labels, all_test_preds_probs)\n",
        "    accuracy = accuracy_score(all_test_labels, all_test_preds_binary)\n",
        "    f1 = f1_score(all_test_labels, all_test_preds_binary)\n",
        "\n",
        "    learned_weights = ensemble_model.get_learned_weights()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# confusion matrix 계산\n",
        "tn, fp, fn, tp = confusion_matrix(all_test_labels, all_test_preds_binary).ravel()\n",
        "\n",
        "print(\"\\n====== Final Test Set Results ======\")\n",
        "print(f\"AUC Score     : {auc:.4f}\")\n",
        "print(f\"Accuracy      : {accuracy:.4f}\")\n",
        "print(f\"F1 Score      : {f1:.4f}\")\n",
        "print(\"\\nConfusion Matrix (Threshold=0.5):\")\n",
        "print(f\"  TP (Fake predicted as Fake) : {tp}\")\n",
        "print(f\"  TN (Real predicted as Real) : {tn}\")\n",
        "print(f\"  FP (Real predicted as Fake) : {fp}\")\n",
        "print(f\"  FN (Fake predicted as Real) : {fn}\")\n",
        "print(f\"  -> Fake detection accuracy   : {tp / (tp + fn):.4f}\")\n",
        "print(f\"  -> Real detection accuracy   : {tn / (tn + fp):.4f}\")\n",
        "\n",
        "print(\"\\nLearned Weights for base models:\")\n",
        "for model_name, weight in zip(BASE_MODEL_PROB_COLUMNS, learned_weights):\n",
        "    print(f\"  - {model_name}: {weight:.4f}\")\n",
        "print(\"====================================\\n\")\n"
      ],
      "metadata": {
        "id": "jf2Haik9Ogrf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fff1751b-021e-4da3-d4a8-6e84f547371c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====== Final Test Set Results ======\n",
            "AUC Score     : 1.0000\n",
            "Accuracy      : 0.9667\n",
            "F1 Score      : 0.9789\n",
            "\n",
            "Confusion Matrix (Threshold=0.5):\n",
            "  TP (Fake predicted as Fake) : 93\n",
            "  TN (Real predicted as Real) : 23\n",
            "  FP (Real predicted as Fake) : 0\n",
            "  FN (Fake predicted as Real) : 4\n",
            "  -> Fake detection accuracy   : 0.9588\n",
            "  -> Real detection accuracy   : 1.0000\n",
            "\n",
            "Learned Weights for base models:\n",
            "  - model_A_prob: 0.0082\n",
            "  - model_B_prob: 0.9606\n",
            "  - model_C_prob: 0.0057\n",
            "  - model_D_prob: 0.0095\n",
            "  - model_E_prob: 0.0160\n",
            "====================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke6W9cXipj6z",
        "outputId": "3dc5ca40-cf59-4525-c6af-833bc176b398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# softVoting\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# --- 설정 (사용자 환경에 맞게 수정) ---\n",
        "CSV_FILE_PATHS = {\n",
        "    'FreqNet': '/content/drive/MyDrive/deepfakedetection_csv/FreqNet_Predictions.csv',\n",
        "    'GenConViT': '/content/drive/MyDrive/deepfakedetection_csv/GenConViT_Predictions.csv',\n",
        "    'CaFft': '/content/drive/MyDrive/deepfakedetection_csv/CaFft_predictions.csv',\n",
        "    'face-x-ray': '/content/drive/MyDrive/deepfakedetection_csv/face-x-ray_predictions.csv',\n",
        "    'cnn-rnn': '/content/drive/MyDrive/deepfakedetection_csv/ResNext&LSTM_predictions.csv'\n",
        "}\n",
        "COLUMN_NAMES = {\n",
        "    'video_id': 'video_id',\n",
        "    'FreqNet': {\n",
        "        'fake_prob': 'fake_prob',\n",
        "        'true_label': 'true_label'\n",
        "    },\n",
        "    'GenConViT': {\n",
        "        'fake_prob': 'fake_prob'\n",
        "    },\n",
        "    'CaFft': {\n",
        "        'fake_prob': 'fake_prob'\n",
        "    },\n",
        "    'face-x-ray': {\n",
        "    'fake_prob': 'fake_prob'\n",
        "    },\n",
        "    'cnn-rnn': {\n",
        "    'fake_prob': 'fake_prob'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Soft Voting 시 각 모델에 부여할 가중치\n",
        "MODEL_WEIGHTS = {\n",
        "    'FreqNet': 0.0082,\n",
        "    'GenConViT': 0.9613,\n",
        "    'CaFft': 0.0057,\n",
        "    'face-x-ray': 0.0088,\n",
        "    'cnn-rnn': 0.016\n",
        "\n",
        "} # or None\n",
        "# AWARE-NET 방식으로 가중치를 학습시키려면 이전의 train_adaptive_ensemble.py 코드를 활용\n",
        "\n",
        "# 최종 예측을 위한 임계값\n",
        "THRESHOLD = 0.5\n",
        "# --- 설정 끝 ---\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    logging.info(\"--- Soft Voting 앙상블 시작 ---\")\n",
        "\n",
        "    loaded_dfs = {}\n",
        "    model_names_loaded = []\n",
        "\n",
        "    for model_name, csv_path in CSV_FILE_PATHS.items():\n",
        "        try:\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # 필요한 컬럼만 선택하고 컬럼 이름 통일 (fake_prob_{model_name}, true_label)\n",
        "            cols_to_select = {COLUMN_NAMES['video_id']: 'video_id'}\n",
        "            if 'fake_prob' in COLUMN_NAMES[model_name]:\n",
        "                cols_to_select[COLUMN_NAMES[model_name]['fake_prob']] = f'fake_prob_{model_name}'\n",
        "            else:\n",
        "                logging.error(f\"'{model_name}'에 대한 fake_prob 컬럼 이름이 COLUMN_NAMES에 정의되지 않았습니다.\")\n",
        "                continue\n",
        "\n",
        "            if not model_names_loaded and 'true_label' in COLUMN_NAMES[model_name]:\n",
        "                 cols_to_select[COLUMN_NAMES[model_name]['true_label']] = 'true_label'\n",
        "\n",
        "            df_selected = df[list(cols_to_select.keys())].rename(columns=cols_to_select)\n",
        "            loaded_dfs[model_name] = df_selected\n",
        "            model_names_loaded.append(model_name)\n",
        "            logging.info(f\"'{csv_path}' 로드 완료. {len(df_selected)}개 샘플, 컬럼: {df_selected.columns.tolist()}\")\n",
        "        except FileNotFoundError:\n",
        "            logging.error(f\"파일을 찾을 수 없습니다: {csv_path}. 이 모델은 앙상블에서 제외됩니다.\")\n",
        "        except KeyError as e:\n",
        "            logging.error(f\"'{csv_path}' 파일에서 필요한 컬럼을 찾을 수 없습니다: {e}. 이 모델은 앙상블에서 제외됩니다.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"'{csv_path}' 파일 로드 중 에러 발생: {e}. 이 모델은 앙상블에서 제외됩니다.\")\n",
        "\n",
        "    if len(model_names_loaded) < 2:\n",
        "        logging.error(\"앙상블을 수행하기에 충분한 모델 예측 결과를 로드하지 못했습니다. (최소 2개 필요)\")\n",
        "        exit()\n",
        "\n",
        "    label_mapping = {'REAL': 0, 'FAKE': 1}\n",
        "    for model_name, df in loaded_dfs.items():\n",
        "        if 'true_label' in df.columns:\n",
        "            df['true_label'] = df['true_label'].map(label_mapping)\n",
        "    final_df = loaded_dfs[model_names_loaded[0]].copy()\n",
        "    if 'true_label' not in final_df.columns:\n",
        "        for mn in model_names_loaded[1:]: # 나머지 모델들 순회\n",
        "            if 'true_label' in loaded_dfs[mn].columns:\n",
        "                final_df = pd.merge(final_df, loaded_dfs[mn][['video_id', 'true_label']], on=COLUMN_NAMES['video_id'], how='left')\n",
        "\n",
        "                if 'true_label' in final_df.columns:\n",
        "                     logging.info(f\"'true_label' 컬럼을 '{mn}' 모델의 CSV에서 가져왔습니다.\")\n",
        "                     break\n",
        "        if 'true_label' not in final_df.columns:\n",
        "            logging.error(\"'true_label' 컬럼을 어떤 CSV에서도 찾을 수 없습니다. 성능 평가가 불가능합니다.\")\n",
        "            exit()\n",
        "\n",
        "\n",
        "    for i in range(1, len(model_names_loaded)):\n",
        "        model_name_to_merge = model_names_loaded[i]\n",
        "        df_to_merge = loaded_dfs[model_name_to_merge][['video_id', f'fake_prob_{model_name_to_merge}']]\n",
        "        final_df = pd.merge(final_df, df_to_merge, on=COLUMN_NAMES['video_id'], how='inner')\n",
        "\n",
        "    logging.info(f\"모든 CSV 병합 완료. 최종 {len(final_df)}개 샘플로 앙상블 수행.\")\n",
        "    if final_df.empty:\n",
        "        logging.error(\"병합 후 남은 데이터가 없습니다. video_id가 일치하는지 확인하세요.\")\n",
        "        exit()\n",
        "\n",
        "    # 가중치 설정\n",
        "    if MODEL_WEIGHTS is None: #\n",
        "        num_models = len(model_names_loaded)\n",
        "        weights = {model_name: 1/num_models for model_name in model_names_loaded}\n",
        "        logging.info(f\"동일 가중치 사용: {weights}\")\n",
        "    else:\n",
        "        weights = MODEL_WEIGHTS\n",
        "        logging.info(f\"사용자 정의 가중치 사용: {weights}\")\n",
        "        if set(weights.keys()) != set(model_names_loaded):\n",
        "            logging.warning(\"MODEL_WEIGHTS에 정의된 모델과 실제 로드된 모델이 일치하지 않습니다. 동일 가중치로 대체합니다.\")\n",
        "            num_models = len(model_names_loaded)\n",
        "            weights = {model_name: 1/num_models for model_name in model_names_loaded}\n",
        "\n",
        "\n",
        "    # 앙상블 예측 확률 계산\n",
        "    final_df['ensemble_fake_prob'] = 0.0\n",
        "    for model_name in model_names_loaded:\n",
        "        prob_col = f'fake_prob_{model_name}'\n",
        "        if prob_col in final_df.columns:\n",
        "            final_df['ensemble_fake_prob'] += final_df[prob_col].fillna(0) * weights.get(model_name, 0)\n",
        "        else:\n",
        "            logging.warning(f\"'{prob_col}' 컬럼이 병합된 DataFrame에 없습니다. '{model_name}' 모델은 앙상블에서 제외됩니다.\")\n",
        "\n",
        "    final_df['ensemble_prediction'] = (final_df['ensemble_fake_prob'] > THRESHOLD).astype(int)\n",
        "\n",
        "    if 'true_label' in final_df.columns:\n",
        "        y_true = final_df['true_label']\n",
        "        y_pred_prob_ensemble = final_df['ensemble_fake_prob']\n",
        "        y_pred_binary_ensemble = final_df['ensemble_prediction']\n",
        "\n",
        "        eval_df = final_df.dropna(subset=['true_label', 'ensemble_fake_prob'])\n",
        "        if not eval_df.empty:\n",
        "            y_true_eval = eval_df['true_label']\n",
        "            y_pred_prob_eval = eval_df['ensemble_fake_prob']\n",
        "            y_pred_binary_eval = eval_df['ensemble_prediction']\n",
        "\n",
        "            auc = roc_auc_score(y_true_eval, y_pred_prob_eval)\n",
        "            accuracy = accuracy_score(y_true_eval, y_pred_binary_eval)\n",
        "            f1 = f1_score(y_true_eval, y_pred_binary_eval)\n",
        "            precision = precision_score(y_true_eval, y_pred_binary_eval, zero_division=0)\n",
        "            recall = recall_score(y_true_eval, y_pred_binary_eval, zero_division=0)\n",
        "\n",
        "            logging.info(\"\\n--- Soft Voting 앙상블 성능 ---\")\n",
        "            logging.info(f\"사용된 모델: {model_names_loaded}\")\n",
        "            logging.info(f\"가중치: {weights}\")\n",
        "            logging.info(f\"AUC: {auc:.4f}\")\n",
        "            logging.info(f\"Accuracy: {accuracy:.4f}\")\n",
        "            logging.info(f\"F1 Score: {f1:.4f}\")\n",
        "            logging.info(f\"Precision: {precision:.4f}\")\n",
        "            logging.info(f\"Recall: {recall:.4f}\")\n",
        "            logging.info(f\"평가에 사용된 샘플 수: {len(eval_df)}\")\n",
        "        else:\n",
        "            logging.warning(\"평가할 수 있는 유효한 데이터가 없습니다 (NaN 값 등으로 인해).\")\n",
        "\n",
        "        logging.info(\"\\n--- 개별 모델 성능 (참고용) ---\")\n",
        "        for model_name in model_names_loaded:\n",
        "            prob_col = f'fake_prob_{model_name}'\n",
        "            if prob_col in final_df.columns:\n",
        "                # NaN 아닌 값들만 평가\n",
        "                model_eval_df = final_df.dropna(subset=['true_label', prob_col])\n",
        "                if not model_eval_df.empty:\n",
        "                    m_y_true = model_eval_df['true_label']\n",
        "                    m_y_pred_prob = model_eval_df[prob_col]\n",
        "                    m_y_pred_binary = (m_y_pred_prob > THRESHOLD).astype(int)\n",
        "\n",
        "                    m_auc = roc_auc_score(m_y_true, m_y_pred_prob)\n",
        "                    m_acc = accuracy_score(m_y_true, m_y_pred_binary)\n",
        "                    m_f1 = f1_score(m_y_true, m_y_pred_binary)\n",
        "                    logging.info(f\"모델: {model_name} | AUC: {m_auc:.4f}, Acc: {m_acc:.4f}, F1: {m_f1:.4f} (샘플 수: {len(model_eval_df)})\")\n",
        "                else:\n",
        "                    logging.info(f\"모델: {model_name} | 평가할 유효 데이터 없음.\")\n",
        "    else:\n",
        "        logging.warning(\"'true_label' 컬럼이 없어 성능 평가를 수행할 수 없습니다.\")\n",
        "\n",
        "    logging.info(\"\\n--- 앙상블 결과 DataFrame (상위 5개 행) ---\")\n",
        "    print(final_df.head())\n",
        "\n",
        "    logging.info(\"\\n--- Soft Voting 앙상블 완료 ---\")\n",
        "\n",
        "    final_df.to_csv('ensemble_predictions.csv', index=False)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(\"\\n--- Soft Voting 앙상블 성능 ---\")\n",
        "print(f\"사용된 모델: {model_names_loaded}\")\n",
        "print(f\"가중치: {weights}\")\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"평가에 사용된 샘플 수: {len(eval_df)}\")\n",
        "\n",
        "# Confusion Matrix 출력\n",
        "cm = confusion_matrix(y_true_eval, y_pred_binary_eval)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "print(\"\\n--- Confusion Matrix ---\")\n",
        "print(f\"True Negatives (REAL correctly predicted): {tn}\")\n",
        "print(f\"False Positives (REAL misclassified as FAKE): {fp}\")\n",
        "print(f\"False Negatives (FAKE misclassified as REAL): {fn}\")\n",
        "print(f\"True Positives (FAKE correctly predicted): {tp}\")\n",
        "\n",
        "# 결과 리스트 만들기 **********************************************\n",
        "results = [\n",
        "    (row['video_id'], round(row['ensemble_fake_prob'], 4))\n",
        "    for _, row in final_df.iterrows()\n",
        "]\n",
        "\n",
        "# 리스트 그대로 출력\n",
        "print(\"\\n--- Raw Results (video_id, fake_prob) ---\")\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "-YTsbzztm-cu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d3659d3-4f41-45a1-84ed-e74ccfd13b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         video_id  fake_prob_FreqNet  true_label  fake_prob_GenConViT  \\\n",
            "0  aagfhgtpmv.mp4             0.0000           1             0.946487   \n",
            "1  aapnvogymq.mp4             0.0000           1             0.770607   \n",
            "2  abarnvbtwb.mp4             0.0011           0             0.076319   \n",
            "3  abofeumbvv.mp4             0.9903           1             0.500000   \n",
            "4  abqwwspghj.mp4             0.0000           1             0.992096   \n",
            "\n",
            "   fake_prob_CaFft  fake_prob_face-x-ray  fake_prob_cnn-rnn  \\\n",
            "0         0.205174              0.203639           0.983453   \n",
            "1         0.222363              0.203538           0.001762   \n",
            "2         0.167179              0.210317           0.062986   \n",
            "3         0.489749             -1.000000           0.000248   \n",
            "4         0.520626              0.281806           0.002953   \n",
            "\n",
            "   ensemble_fake_prob  ensemble_prediction  \n",
            "0            0.928555                    1  \n",
            "1            0.743871                    1  \n",
            "2            0.077186                    0  \n",
            "3            0.482766                    0  \n",
            "4            0.959197                    1  \n",
            "\n",
            "--- Soft Voting 앙상블 성능 ---\n",
            "사용된 모델: ['FreqNet', 'GenConViT', 'CaFft', 'face-x-ray', 'cnn-rnn']\n",
            "가중치: {'FreqNet': 0.0082, 'GenConViT': 0.9613, 'CaFft': 0.0057, 'face-x-ray': 0.0088, 'cnn-rnn': 0.016}\n",
            "AUC: 0.9994\n",
            "Accuracy: 0.9424\n",
            "F1 Score: 0.9630\n",
            "Precision: 1.0000\n",
            "Recall: 0.9286\n",
            "평가에 사용된 샘플 수: 399\n",
            "\n",
            "--- Confusion Matrix ---\n",
            "True Negatives (REAL correctly predicted): 77\n",
            "False Positives (REAL misclassified as FAKE): 0\n",
            "False Negatives (FAKE misclassified as REAL): 23\n",
            "True Positives (FAKE correctly predicted): 299\n",
            "\n",
            "--- Raw Results (video_id, fake_prob) ---\n",
            "[('aagfhgtpmv.mp4', 0.9286), ('aapnvogymq.mp4', 0.7439), ('abarnvbtwb.mp4', 0.0772), ('abofeumbvv.mp4', 0.4828), ('abqwwspghj.mp4', 0.9592), ('acifjvzvpm.mp4', 0.9204), ('acqfdwsrhi.mp4', 0.9814), ('acxnxvbsxk.mp4', 0.9815), ('acxwigylke.mp4', 0.9632), ('aczrgyricp.mp4', 0.9675), ('adhsbajydo.mp4', 0.482), ('adohikbdaz.mp4', 0.9681), ('adylbeequz.mp4', 0.9845), ('aelfnikyqj.mp4', 0.019), ('aelzhcnwgf.mp4', 0.9844), ('aettqgevhz.mp4', 0.9802), ('aevrfsexku.mp4', 0.8857), ('afoovlsmtx.mp4', 0.0281), ('agdkmztvby.mp4', 0.9833), ('agqphdxmwt.mp4', 0.974), ('agrmhtjdlk.mp4', 0.3703), ('ahbweevwpv.mp4', 0.8616), ('ahdbuwqxit.mp4', 0.9812), ('ahfazfbntc.mp4', 0.9769), ('ahqqqilsxt.mp4', 0.0483), ('aipfdnwpoo.mp4', 0.5673), ('ajqslcypsw.mp4', 0.091), ('ajwpjhrbcv.mp4', 0.9811), ('aklqzsddfl.mp4', 0.9722), ('aknbdpmgua.mp4', 0.9739), ('aknmpoonls.mp4', 0.9719), ('akvmwkdyuv.mp4', 0.9841), ('akxoopqjqz.mp4', 0.8801), ('akzbnazxtz.mp4', 0.7164), ('aladcziidp.mp4', 0.9544), ('alaijyygdv.mp4', 0.9661), ('alninxcyhg.mp4', 0.9661), ('altziddtxi.mp4', 0.9376), ('alvgwypubw.mp4', 0.9801), ('amaivqofda.mp4', 0.9783), ('amowujxmzc.mp4', 0.9759), ('andaxzscny.mp4', 0.4827), ('aneclqfpbt.mp4', 0.9809), ('anpuvshzoo.mp4', 0.1211), ('aorjvbyxhw.mp4', 0.9814), ('apatcsqejh.mp4', 0.7184), ('apgjqzkoma.mp4', 0.9567), ('apogckdfrz.mp4', 0.9766), ('aqpnvjhuzw.mp4', 0.9119), ('arkroixhey.mp4', 0.9123), ('arlmiizoob.mp4', 0.9601), ('arrhsnjqku.mp4', 0.9799), ('asaxgevnnp.mp4', 0.0652), ('asdpeebotb.mp4', 0.9744), ('aslsvlvpth.mp4', 0.9621), ('asmpfjfzif.mp4', 0.9879), ('asvcrfdpnq.mp4', 0.89), ('atkdltyyen.mp4', 0.0257), ('atvmxvwyns.mp4', 0.4825), ('atxvxouljq.mp4', 0.9621), ('atyntldecu.mp4', 0.9855), ('atzdznmder.mp4', 0.9421), ('aufmsmnoye.mp4', 0.9888), ('augtsuxpzc.mp4', 0.9546), ('avfitoutyn.mp4', 0.988), ('avgiuextiz.mp4', 0.8292), ('avibnnhwhp.mp4', 0.7534), ('avmjormvsx.mp4', 0.0274), ('avnqydkqjj.mp4', 0.9725), ('avssvvsdhz.mp4', 0.9278), ('avtycwsgyb.mp4', 0.9728), ('avvdgsennp.mp4', 0.4829), ('avywawptfc.mp4', 0.9678), ('awhmfnnjih.mp4', 0.9827), ('awnwkrqibf.mp4', 0.9823), ('awukslzjra.mp4', 0.9813), ('axczxisdtb.mp4', 0.9834), ('axntxmycwd.mp4', 0.0313), ('axoygtekut.mp4', 0.8801), ('axwgcsyphv.mp4', 0.482), ('axwovszumc.mp4', 0.9485), ('aybgughjxh.mp4', 0.0396), ('aybumesmpk.mp4', 0.0717), ('ayqvfdhslr.mp4', 0.9247), ('aytzyidmgs.mp4', 0.0556), ('azpuxunqyo.mp4', 0.9813), ('azsmewqghg.mp4', 0.8542), ('bahdpoesir.mp4', 0.9359), ('bbhpvrmbse.mp4', 0.7391), ('bbhtdfuqxq.mp4', 0.8305), ('bbvgxeczei.mp4', 0.4821), ('bchnbulevv.mp4', 0.8573), ('bctvsmddgq.mp4', 0.9398), ('bdbhekrrwo.mp4', 0.9851), ('bddjdhzfze.mp4', 0.0651), ('bdgipnyobr.mp4', 0.7338), ('bdnaqemxmr.mp4', 0.0797), ('bdxuhamuqx.mp4', 0.9624), ('beboztfcme.mp4', 0.0252), ('bejhvclboh.mp4', 0.0397), ('benmsfzfaz.mp4', 0.9796), ('beyebyhrph.mp4', 0.1017), ('bffwsjxghk.mp4', 0.0154), ('bgaogsjehq.mp4', 0.8605), ('bggsurpgpr.mp4', 0.9621), ('bghphrsfxf.mp4', 0.9578), ('bgmlwsoamc.mp4', 0.3376), ('bguwlyazau.mp4', 0.5559), ('bgvhtpzknn.mp4', 0.1876), ('bgwmmujlmc.mp4', 0.0327), ('bhaaboftbc.mp4', 0.5339), ('bhbdugnurr.mp4', 0.9631), ('bhpwpydzpo.mp4', 0.9751), ('bhsluedavd.mp4', 0.9549), ('bilnggbxgu.mp4', 0.1278), ('bjjbwsqjir.mp4', 0.9517), ('bjkmjilrxp.mp4', 0.9874), ('bjsmaqefoi.mp4', 0.9649), ('bkmdzhfzfh.mp4', 0.9841), ('bkvetcojbt.mp4', 0.9478), ('bkwxhglwct.mp4', 0.9716), ('blpchvmhxx.mp4', 0.9805), ('blzydqdfem.mp4', 0.973), ('bmbbkwmxqj.mp4', 0.8751), ('bmehkyanbj.mp4', 0.9009), ('bmhvktyiwp.mp4', 0.982), ('bmioepcpsx.mp4', 0.8505), ('bmjmjmbglm.mp4', 0.6491), ('bmjzrlszhi.mp4', 0.1281), ('bnbuonyoje.mp4', 0.8957), ('bndybcqhfr.mp4', 0.606), ('bnjcdrfuov.mp4', 0.8348), ('bntlodcfeg.mp4', 0.9764), ('bofqajtwve.mp4', 0.9811), ('boovltmuwi.mp4', 0.7149), ('bopqhhalml.mp4', 0.9785), ('bourlmzsio.mp4', 0.9655), ('bpapbctoao.mp4', 0.2252), ('bpwzipqtxf.mp4', 0.7691), ('bpxckdzddv.mp4', 0.983), ('bqdjzqhcft.mp4', 0.9776), ('bqeiblbxtl.mp4', 0.9815), ('bqhtpqmmqp.mp4', 0.9556), ('bqkdbcqjvb.mp4', 0.4824), ('bqnymlsayl.mp4', 0.8652), ('bqqpbzjgup.mp4', 0.9324), ('bqtuuwzdtr.mp4', 0.9658), ('brhalypwoo.mp4', 0.363), ('brvqtabyxj.mp4', 0.9847), ('brwrlczjvi.mp4', 0.0841), ('bseamdrpbj.mp4', 0.8359), ('bsfmwclnqy.mp4', 0.9824), ('bsqgziaylx.mp4', 0.4287), ('btiysiskpf.mp4', 0.983), ('btjlfpzbdu.mp4', 0.8994), ('btjwbtsgln.mp4', 0.9669), ('btmsngnqhv.mp4', 0.9825), ('btohlidmru.mp4', 0.9731), ('btugrnoton.mp4', 0.9842), ('btunxncpjh.mp4', 0.8195), ('btxlttbpkj.mp4', 0.964), ('bulkxhhknf.mp4', 0.0543), ('bvgwelbeof.mp4', 0.9614), ('bvzjkezkms.mp4', 0.8241), ('bweezhfpzp.mp4', 0.9828), ('bwhlgysghg.mp4', 0.0472), ('bwipwzzxxu.mp4', 0.0253), ('bwuwstvsbw.mp4', 0.9925), ('bxzakyopjf.mp4', 0.1173), ('bydaidkpdp.mp4', 0.9811), ('byfenovjnf.mp4', 0.4485), ('byijojkdba.mp4', 0.8629), ('byofowlkki.mp4', 0.9798), ('byqzyxifza.mp4', 0.9934), ('byunigvnay.mp4', 0.9357), ('byyqectxqa.mp4', 0.8832), ('bzmdrafeex.mp4', 0.6105), ('bzythlfnhq.mp4', 0.0357), ('caifxvsozs.mp4', 0.2117), ('caqbrkogkb.mp4', 0.8778), ('cbbibzcoih.mp4', 0.9638), ('cbltdtxglo.mp4', 0.8941), ('ccfoszqabv.mp4', 0.1417), ('ccmonzqfrz.mp4', 0.9757), ('cdaxixbosp.mp4', 0.7137), ('cdbsbdymzd.mp4', 0.9828), ('cdphtzqrvp.mp4', 0.9845), ('cdyakrxkia.mp4', 0.4828), ('cepxysienc.mp4', 0.946), ('cettndmvzl.mp4', 0.9809), ('ceymbecxnj.mp4', 0.9219), ('cferslmfwh.mp4', 0.4914), ('cffffbcywc.mp4', 0.5129), ('cfxkpiweqt.mp4', 0.1173), ('cfyduhpbps.mp4', 0.9802), ('cglxirfaey.mp4', 0.9841), ('cgvrgibpfo.mp4', 0.9556), ('chtapglbcj.mp4', 0.0474), ('chviwxsfhg.mp4', 0.2037), ('chzieimrwu.mp4', 0.9685), ('ciyoudyhly.mp4', 0.1726), ('cizlkenljw.mp4', 0.2329), ('ckbdwedgmc.mp4', 0.8683), ('ckjaibzfxa.mp4', 0.0933), ('ckkuyewywx.mp4', 0.2685), ('cknyxaqouy.mp4', 0.9819), ('cksanfsjhc.mp4', 0.965), ('clihsshdkq.mp4', 0.9837), ('clrycekyst.mp4', 0.0398), ('cmbzllswnl.mp4', 0.1064), ('cmxcfkrjiv.mp4', 0.6731), ('cnilkgvfei.mp4', 0.9378), ('coadfnerlk.mp4', 0.9798), ('cobjrlugvp.mp4', 0.07), ('covdcysmbi.mp4', 0.9796), ('cpjxareypw.mp4', 0.0621), ('cppdvdejkc.mp4', 0.0447), ('cprhtltsjp.mp4', 0.0328), ('cqfugiqupm.mp4', 0.9781), ('cqhngvpgyi.mp4', 0.9597), ('cqrskwiqng.mp4', 0.9875), ('crezycjqyk.mp4', 0.0134), ('crktehraph.mp4', 0.9766), ('crzfebnfgb.mp4', 0.9685), ('cthdnahrkh.mp4', 0.9643), ('ctpqeykqdp.mp4', 0.9773), ('cttqtsjvgn.mp4', 0.9785), ('ctzmavwror.mp4', 0.8567), ('curpwogllm.mp4', 0.9105), ('cuzrgrbvil.mp4', 0.9793), ('cvaksbpssm.mp4', 0.9603), ('cwbacdwrzo.mp4', 0.8567), ('cwrtyzndpx.mp4', 0.9938), ('cwsbspfzck.mp4', 0.9617), ('cwwandrkus.mp4', 0.9958), ('cxfujlvsuw.mp4', 0.984), ('cxrfacemmq.mp4', 0.982), ('cxttmymlbn.mp4', 0.8845), ('cyboodqqyr.mp4', 0.9919), ('cycacemkmt.mp4', 0.4821), ('cyclgfjdrv.mp4', 0.992), ('cyxlcuyznd.mp4', 0.027), ('czfunozvwp.mp4', 0.8041), ('czkdanyadc.mp4', 0.9554), ('czmqpxrqoh.mp4', 0.4827), ('dafhtipaml.mp4', 0.731), ('dakiztgtnw.mp4', 0.0549), ('dakqwktlbi.mp4', 0.9764), ('dbhoxkblzx.mp4', 0.9841), ('dbhrpizyeq.mp4', 0.9155), ('dbnygxtwek.mp4', 0.1954), ('dboxtiehng.mp4', 0.969), ('dbtbbhakdv.mp4', 0.0948), ('dbzcqmxzaj.mp4', 0.977), ('dbzpcjntve.mp4', 0.9868), ('dcamvmuors.mp4', 0.9544), ('dcuiiorugd.mp4', 0.7209), ('ddepeddixj.mp4', 0.0328), ('ddhfabwpuz.mp4', 0.9822), ('ddjggcasdw.mp4', 0.9586), ('ddpvuimigj.mp4', 0.9498), ('ddqccgmtka.mp4', 0.9463), ('degpbqvcay.mp4', 0.5824), ('deywhkarol.mp4', 0.8302), ('deyyistcrd.mp4', 0.9833), ('dfbpceeaox.mp4', 0.9807), ('dgmevclvzy.mp4', 0.9118), ('dgxrqjdomn.mp4', 0.9884), ('dgzklxjmix.mp4', 0.9785), ('dhcndnuwta.mp4', 0.1867), ('dhcselezer.mp4', 0.9652), ('dhevettufk.mp4', 0.883), ('dhjmzhrcav.mp4', 0.9817), ('dhkwmjxwrn.mp4', 0.8249), ('dhoqofwoxa.mp4', 0.4827), ('dhxctgyoqj.mp4', 0.1851), ('diomeixhrg.mp4', 0.9804), ('diopzaywor.mp4', 0.9825), ('diqraixiov.mp4', 0.3464), ('diuzrpqjli.mp4', 0.8572), ('djvtbgwdcc.mp4', 0.6849), ('djvutyvaio.mp4', 0.4826), ('djxdyjopjd.mp4', 0.0743), ('dkdwxmtpuo.mp4', 0.9243), ('dkhlttuvmx.mp4', 0.4837), ('dkrvorliqc.mp4', 0.9002), ('dkuayagnmc.mp4', 0.056), ('dkwjwbwgey.mp4', 0.9783), ('dkzvdrzcnr.mp4', 0.0721), ('dlpoieqvfb.mp4', 0.0979), ('dlrsbscitn.mp4', 0.6486), ('dnexlwbcxq.mp4', 0.9831), ('dnhvalzvrt.mp4', 0.9801), ('dntkzzzcdh.mp4', 0.9828), ('dnyvfblxpm.mp4', 0.9711), ('doanjploai.mp4', 0.9883), ('dofusvhnib.mp4', 0.9431), ('dozyddhild.mp4', 0.982), ('dptbnjnkdg.mp4', 0.818), ('dptrzdvwpg.mp4', 0.974), ('dqnyszdong.mp4', 0.4846), ('dqppxmoqdl.mp4', 0.8098), ('dqqtjcryjv.mp4', 0.9076), ('dqswpjoepo.mp4', 0.8219), ('dqzreruvje.mp4', 0.9819), ('drcyabprvt.mp4', 0.1002), ('drgjzlxzxj.mp4', 0.9202), ('drsakwyvqv.mp4', 0.8951), ('drtbksnpol.mp4', 0.9669), ('dsdoseflas.mp4', 0.9874), ('dsgpbgsrdm.mp4', 0.8956), ('dsjbknkujw.mp4', 0.0832), ('dsndhujjjb.mp4', 0.9687), ('dtbpmdqvao.mp4', 0.9227), ('dtocdfbwca.mp4', 0.9823), ('dubiroskqn.mp4', 0.9671), ('dulanfulol.mp4', 0.9787), ('duvyaxbzvp.mp4', 0.9738), ('duycddgtrl.mp4', 0.1529), ('duzuusuajr.mp4', 0.9782), ('dvakowbgbt.mp4', 0.943), ('dvumqqhoac.mp4', 0.9654), ('dwediigjit.mp4', 0.9815), ('dxbqjxrhin.mp4', 0.149), ('dxuliowugt.mp4', 0.8169), ('dxuplhwvig.mp4', 0.7894), ('dzieklokdr.mp4', 0.7473), ('dzqwgqewhu.mp4', 0.9828), ('dzvyfiarrq.mp4', 0.7783), ('dzwkmcwkwl.mp4', 0.9782), ('dzyuwjkjui.mp4', 0.145), ('eahlqmfvtj.mp4', 0.9552), ('eajlrktemq.mp4', 0.9792), ('ebchwmwayp.mp4', 0.766), ('ebebgmtlcu.mp4', 0.9632), ('ebeknhudxq.mp4', 0.4826), ('ebkzwjgjhq.mp4', 0.9137), ('ebywfrmhtd.mp4', 0.9301), ('eckvhdusax.mp4', 0.0133), ('ecnihjlfyt.mp4', 0.9757), ('ecujsjhscd.mp4', 0.0441), ('ecuvtoltue.mp4', 0.9831), ('ecwaxgutkc.mp4', 0.7778), ('eczrseixwq.mp4', 0.9189), ('edyncaijwx.mp4', 0.1946), ('eebrkicpry.mp4', 0.9889), ('eebserckhh.mp4', 0.9915), ('eejswgycjc.mp4', 0.9888), ('eekozbeafq.mp4', 0.7219), ('eepezmygaq.mp4', 0.8601), ('eeyhxisdfh.mp4', 0.9159), ('efdyrflcpg.mp4', 0.9804), ('efwfxwwlbw.mp4', 0.1656), ('egbbcxcuqy.mp4', 0.9857), ('eggbjzxnmg.mp4', 0.2365), ('egghxjjmfg.mp4', 0.0502), ('ehbnclaukr.mp4', 0.7506), ('ehccixxzoe.mp4', 0.2833), ('ehdkmxgtxh.mp4', 0.9207), ('ehevsxtecd.mp4', 0.9785), ('ehfiekigla.mp4', 0.9817), ('ehieahnhte.mp4', 0.9719), ('ehtdtkmmli.mp4', 0.0814), ('eiriyukqqy.mp4', 0.9849), ('eivxffliio.mp4', 0.9424), ('eiwopxzjfn.mp4', 0.8351), ('eixwxvxbbn.mp4', 0.983), ('ejkqesyvam.mp4', 0.9164), ('ekcrtigpab.mp4', 0.156), ('ekhacizpah.mp4', 0.9175), ('ekkdjkirzq.mp4', 0.8283), ('elginszwtk.mp4', 0.8658), ('ellavthztb.mp4', 0.089), ('elvvackpjh.mp4', 0.9816), ('emaalmsonj.mp4', 0.9869), ('emfbhytfhc.mp4', 0.9825), ('emgjphonqb.mp4', 0.845), ('ensyyivobf.mp4', 0.5304), ('eoewqcpbgt.mp4', 0.4829), ('eprybmbpba.mp4', 0.9673), ('epymyyiblu.mp4', 0.9768), ('eqjscdagiv.mp4', 0.9775), ('eqnoqyfquo.mp4', 0.2866), ('eqvuznuwsa.mp4', 0.8963), ('erlvuvjsjf.mp4', 0.1422), ('erqgqacbqe.mp4', 0.9758), ('errocgcham.mp4', 0.9823), ('esckbnkkvb.mp4', 0.7412), ('esgftaficx.mp4', 0.984), ('esnntzzajv.mp4', 0.909), ('esxrvsgpvb.mp4', 0.9204), ('esyhwdfnxs.mp4', 0.482), ('esyrimvzsa.mp4', 0.989), ('etdcqxabww.mp4', 0.9638), ('etejaapnxh.mp4', 0.9797), ('etmcruaihe.mp4', 0.7782), ('etohcvnzbj.mp4', 0.899), ('eudeqjhdfd.mp4', 0.2543), ('eukvucdetx.mp4', 0.9932)]\n"
          ]
        }
      ]
    }
  ]
}
